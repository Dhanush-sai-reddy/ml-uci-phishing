{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPpJzi5o3wceUTXhNjoxYYI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhanush-sai-reddy/ml-uci-phishing/blob/main/Newone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Phishing Detection using UCI Phishing Websites Dataset\n",
        "\n",
        "- Downloads dataset from Kaggle via kagglehub\n",
        "- Trains RandomForest + XGBoost + VotingClassifier\n",
        "- Extracts URL + HTML/JS-based features for real-time prediction\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import re\n",
        "import warnings\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "import kagglehub\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "def load_dataset():\n",
        "    \"\"\"Download and load the UCI phishing dataset from Kaggle.\"\"\"\n",
        "    path = kagglehub.dataset_download(\"isatish/phishing-dataset-uci-ml-csv\")\n",
        "    csv_files = [f for f in os.listdir(path) if f.endswith(\".csv\")]\n",
        "    if not csv_files:\n",
        "        raise FileNotFoundError(\"No CSV file found in downloaded Kaggle dataset path.\")\n",
        "    df = pd.read_csv(os.path.join(path, csv_files[0]))\n",
        "    return df\n",
        "\n",
        "\n",
        "def train_models(df):\n",
        "    \"\"\"\n",
        "    Train RandomForest, XGBoost and a soft Voting classifier.\n",
        "    Returns: (X_columns, voting_model)\n",
        "    \"\"\"\n",
        "    X = df.drop(\"Result\", axis=1)\n",
        "    y = (df[\"Result\"] == 1).astype(int)  # Convert {1, -1} -> {1, 0}\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    rf = RandomForestClassifier(\n",
        "        n_estimators=150, random_state=42, n_jobs=-1\n",
        "    )\n",
        "    rf.fit(X_train, y_train)\n",
        "\n",
        "    xgb = XGBClassifier(\n",
        "        n_estimators=150,\n",
        "        max_depth=5,\n",
        "        learning_rate=0.1,\n",
        "        eval_metric=\"logloss\",\n",
        "        random_state=42,\n",
        "    )\n",
        "    xgb.fit(X_train, y_train)\n",
        "\n",
        "    voting = VotingClassifier(\n",
        "        estimators=[(\"rf\", rf), (\"xgb\", xgb)],\n",
        "        voting=\"soft\",\n",
        "    )\n",
        "    voting.fit(X_train, y_train)\n",
        "\n",
        "    print(\"RandomForest accuracy:\", accuracy_score(y_test, rf.predict(X_test)))\n",
        "    print(\"XGBoost accuracy:     \", accuracy_score(y_test, xgb.predict(X_test)))\n",
        "    print(\"Voting clf accuracy:  \", accuracy_score(y_test, voting.predict(X_test)))\n",
        "\n",
        "    return X.columns.tolist(), voting\n",
        "\n",
        "\n",
        "def extract_features(url, feature_names):\n",
        "    \"\"\"\n",
        "    Extract URL + HTML/JS-based features for a given URL.\n",
        "    Returns a dict with keys matching the dataset feature names.\n",
        "    \"\"\"\n",
        "    features = {}\n",
        "    parsed = urlparse(url)\n",
        "    domain = parsed.netloc\n",
        "    domain_only = domain.replace(\"www.\", \"\")\n",
        "\n",
        "    # ----------------- URL-BASED FEATURES -----------------\n",
        "    # having_IP_Address\n",
        "    features[\"having_IP_Address\"] = 1 if re.match(\n",
        "        r\"\\d+\\.\\d+\\.\\d+\\.\\d+\", domain\n",
        "    ) else -1\n",
        "\n",
        "    # URL_Length\n",
        "    L = len(url)\n",
        "    if L > 75:\n",
        "        features[\"URL_Length\"] = 1\n",
        "    elif 54 <= L <= 75:\n",
        "        features[\"URL_Length\"] = 0\n",
        "    else:\n",
        "        features[\"URL_Length\"] = -1\n",
        "\n",
        "    # Shortining_Service\n",
        "    shorteners = (\n",
        "        r\"(bit\\.ly|goo\\.gl|tinyurl|shorte\\.st|t\\.co|is\\.gd|ow\\.ly)\"\n",
        "    )\n",
        "    features[\"Shortining_Service\"] = 1 if re.search(shorteners, url) else -1\n",
        "\n",
        "    # having_At_Symbol\n",
        "    features[\"having_At_Symbol\"] = 1 if \"@\" in url else -1\n",
        "\n",
        "    # double_slash_redirecting\n",
        "    features[\"double_slash_redirecting\"] = 1 if url.count(\"//\") > 1 else -1\n",
        "\n",
        "    # Prefix_Suffix\n",
        "    features[\"Prefix_Suffix\"] = 1 if \"-\" in domain else -1\n",
        "\n",
        "    # having_Sub_Domain\n",
        "    dots = domain.count(\".\")\n",
        "    if dots >= 3:\n",
        "        features[\"having_Sub_Domain\"] = 1\n",
        "    elif dots == 2:\n",
        "        features[\"having_Sub_Domain\"] = 0\n",
        "    else:\n",
        "        features[\"having_Sub_Domain\"] = -1\n",
        "\n",
        "    # HTTPS_token\n",
        "    features[\"HTTPS_token\"] = 1 if \"https\" in domain.lower() else -1\n",
        "\n",
        "    # port\n",
        "    features[\"port\"] = (\n",
        "        1 if parsed.port not in [80, 443, None] else -1\n",
        "    )\n",
        "\n",
        "    # SSLfinal_State (approx from scheme only)\n",
        "    features[\"SSLfinal_State\"] = (\n",
        "        1 if parsed.scheme == \"https\" else -1\n",
        "    )\n",
        "\n",
        "    # ----------------- HTML / JS FEATURES -----------------\n",
        "    try:\n",
        "        response = requests.get(url, timeout=4)\n",
        "        html = response.text\n",
        "        soup = BeautifulSoup(html, \"lxml\")\n",
        "    except Exception:\n",
        "        # If page can't be loaded, fill missing with 0 later\n",
        "        for col in feature_names:\n",
        "            if col not in features:\n",
        "                features[col] = 0\n",
        "        return features\n",
        "\n",
        "    anchors = soup.find_all(\"a\", href=True)\n",
        "    imgs = soup.find_all(\"img\", src=True)\n",
        "    scripts = soup.find_all(\"script\", src=True)\n",
        "    links = soup.find_all(\"link\", href=True)\n",
        "    iframes = soup.find_all(\"iframe\")\n",
        "\n",
        "    # Request_URL\n",
        "    total = len(imgs) + len(scripts)\n",
        "    external = 0\n",
        "    for tag in imgs + scripts:\n",
        "        src = tag.get(\"src\")\n",
        "        if src and src.startswith(\"http\") and domain_only not in src:\n",
        "            external += 1\n",
        "    ratio = external / total if total != 0 else 0\n",
        "    if ratio > 0.61:\n",
        "        features[\"Request_URL\"] = 1\n",
        "    elif 0.22 <= ratio <= 0.61:\n",
        "        features[\"Request_URL\"] = 0\n",
        "    else:\n",
        "        features[\"Request_URL\"] = -1\n",
        "\n",
        "    # URL_of_Anchor\n",
        "    total = len(anchors)\n",
        "    external = 0\n",
        "    for a in anchors:\n",
        "        href = a[\"href\"]\n",
        "        if href.startswith(\"http\") and domain_only not in href:\n",
        "            external += 1\n",
        "    ratio = external / total if total != 0 else 0\n",
        "    if ratio > 0.67:\n",
        "        features[\"URL_of_Anchor\"] = 1\n",
        "    elif ratio >= 0.31:\n",
        "        features[\"URL_of_Anchor\"] = 0\n",
        "    else:\n",
        "        features[\"URL_of_Anchor\"] = -1\n",
        "\n",
        "    # Links_in_tags\n",
        "    total = len(scripts) + len(links)\n",
        "    external = 0\n",
        "    for tag in scripts + links:\n",
        "        src = tag.get(\"src\") or tag.get(\"href\")\n",
        "        if src and src.startswith(\"http\") and domain_only not in src:\n",
        "            external += 1\n",
        "    ratio = external / total if total != 0 else 0\n",
        "    if ratio > 0.61:\n",
        "        features[\"Links_in_tags\"] = 1\n",
        "    elif ratio >= 0.22:\n",
        "        features[\"Links_in_tags\"] = 0\n",
        "    else:\n",
        "        features[\"Links_in_tags\"] = -1\n",
        "\n",
        "    # SFH\n",
        "    forms = soup.find_all(\"form\")\n",
        "    if len(forms) == 0:\n",
        "        features[\"SFH\"] = 1\n",
        "    else:\n",
        "        action = forms[0].get(\"action\", \"\")\n",
        "        if action in [\"\", \"about:blank\"]:\n",
        "            features[\"SFH\"] = 1\n",
        "        elif domain_only not in action:\n",
        "            features[\"SFH\"] = 1\n",
        "        else:\n",
        "            features[\"SFH\"] = -1\n",
        "\n",
        "    # Submitting_to_email\n",
        "    features[\"Submitting_to_email\"] = 1 if \"mailto:\" in html else -1\n",
        "\n",
        "    # Abnormal_URL\n",
        "    features[\"Abnormal_URL\"] = -1 if domain_only in html else 1\n",
        "\n",
        "    # Redirect\n",
        "    if \"window.location\" in html or \"meta refresh\" in html.lower():\n",
        "        features[\"Redirect\"] = 1\n",
        "    else:\n",
        "        features[\"Redirect\"] = -1\n",
        "\n",
        "    # on_mouseover\n",
        "    features[\"on_mouseover\"] = 1 if \"onmouseover\" in html.lower() else -1\n",
        "\n",
        "    # RightClick\n",
        "    features[\"RightClick\"] = 1 if \"event.button==2\" in html else -1\n",
        "\n",
        "    # popUpWidnow\n",
        "    features[\"popUpWidnow\"] = 1 if \"window.open\" in html else -1\n",
        "\n",
        "    # Iframe\n",
        "    features[\"Iframe\"] = 1 if len(iframes) > 0 else -1\n",
        "\n",
        "    # Any dataset features not explicitly set: default 0\n",
        "    for col in feature_names:\n",
        "        if col not in features:\n",
        "            features[col] = 0\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def predict_url(url, feature_names, model):\n",
        "    \"\"\"Return prediction and probability for a given URL.\"\"\"\n",
        "    feat = extract_features(url, feature_names)\n",
        "    feat_df = pd.DataFrame([feat])[feature_names]\n",
        "    prob = model.predict_proba(feat_df)[0, 1]\n",
        "    pred = model.predict(feat_df)[0]\n",
        "    label = \"PHISHING\" if pred == 1 else \"LEGITIMATE\"\n",
        "    return label, float(prob)\n",
        "\n",
        "\n",
        "def main():\n",
        "    df = load_dataset()\n",
        "    print(\"Dataset loaded:\", df.shape)\n",
        "\n",
        "    feature_names, model = train_models(df)\n",
        "\n",
        "    # Example test URLs\n",
        "    test_urls = [\n",
        "        \"https://google.com\",\n",
        "        \"http://198.54.23.11/login/secure\",\n",
        "        \"https://paypal-security-update.com/login\",\n",
        "        \"http://bit.ly/3xYz\",\n",
        "    ]\n",
        "\n",
        "    for u in test_urls:\n",
        "        label, prob = predict_url(u, feature_names, model)\n",
        "        print(f\"\\nURL: {u}\")\n",
        "        print(f\"Prediction: {label}\")\n",
        "        print(f\"Phishing probability: {prob:.4f}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "2sZqG325L4d1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}