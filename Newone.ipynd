{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP8CcAFwplFV48Aie60aztX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhanush-sai-reddy/ml-uci-phishing/blob/main/Newone.ipynd\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60x_FdRZJ0bB",
        "outputId": "c6bd7043-73cd-46f6-c847-3dcc64c5f415"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/isatish/phishing-dataset-uci-ml-csv?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 110k/110k [00:00<00:00, 49.9MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n",
            "Dataset Loaded: (11055, 32)\n",
            "Columns: ['id', 'having_IP_Address', 'URL_Length', 'Shortining_Service', 'having_At_Symbol', 'double_slash_redirecting', 'Prefix_Suffix', 'having_Sub_Domain', 'SSLfinal_State', 'Domain_registeration_length', 'Favicon', 'port', 'HTTPS_token', 'Request_URL', 'URL_of_Anchor', 'Links_in_tags', 'SFH', 'Submitting_to_email', 'Abnormal_URL', 'Redirect', 'on_mouseover', 'RightClick', 'popUpWidnow', 'Iframe', 'age_of_domain', 'DNSRecord', 'web_traffic', 'Page_Rank', 'Google_Index', 'Links_pointing_to_page', 'Statistical_report', 'Result']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Complete!\n",
            "RF: 0.9651741293532339\n",
            "XGB: 0.9669832654907282\n",
            "Voting: 0.9656264133876075\n",
            "\n",
            "======================================\n",
            "URL: https://google.com\n",
            "Phishing Probability: 0.08586694525554776\n",
            "Prediction: LEGITIMATE\n",
            "======================================\n",
            "\n",
            "\n",
            "======================================\n",
            "URL: http://198.54.23.11/login/secure\n",
            "Phishing Probability: 0.17683510445058345\n",
            "Prediction: LEGITIMATE\n",
            "======================================\n",
            "\n",
            "\n",
            "======================================\n",
            "URL: https://paypal-security-update.com/login\n",
            "Phishing Probability: 0.8697185798486073\n",
            "Prediction: PHISHING\n",
            "======================================\n",
            "\n",
            "\n",
            "======================================\n",
            "URL: http://bit.ly/3xYz\n",
            "Phishing Probability: 0.10844977302631985\n",
            "Prediction: LEGITIMATE\n",
            "======================================\n",
            "\n",
            "System Ready. Use predict_url('your_url') to check any site.\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "#  COMPLETE PHISHING DETECTION SYSTEM IN ONE CELL\n",
        "# ============================================================\n",
        "\n",
        "!pip install kagglehub xgboost requests beautifulsoup4 lxml --quiet\n",
        "\n",
        "import kagglehub\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urlparse, urljoin\n",
        "import re\n",
        "import warnings\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ============================================================\n",
        "# 1. DOWNLOAD DATASET\n",
        "# ============================================================\n",
        "path = kagglehub.dataset_download(\"isatish/phishing-dataset-uci-ml-csv\")\n",
        "import os\n",
        "csv_files = [f for f in os.listdir(path) if f.endswith(\".csv\")]\n",
        "df = pd.read_csv(os.path.join(path, csv_files[0]))\n",
        "\n",
        "print(\"Dataset Loaded:\", df.shape)\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "\n",
        "# ============================================================\n",
        "# 2. DATA PREP\n",
        "# ============================================================\n",
        "X = df.drop(\"Result\", axis=1)\n",
        "y = (df[\"Result\"] == 1).astype(int)  # Convert {1,-1} → {1,0}\n",
        "\n",
        "# Train-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# 3. TRAIN MODELS\n",
        "# ============================================================\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=150, random_state=42, n_jobs=-1)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "xgb = XGBClassifier(\n",
        "    n_estimators=150, max_depth=5, learning_rate=0.1,\n",
        "    eval_metric=\"logloss\", random_state=42\n",
        ")\n",
        "xgb.fit(X_train, y_train)\n",
        "\n",
        "voting = VotingClassifier(\n",
        "    estimators=[(\"rf\", rf), (\"xgb\", xgb)],\n",
        "    voting=\"soft\"\n",
        ")\n",
        "voting.fit(X_train, y_train)\n",
        "\n",
        "print(\"\\nTraining Complete!\")\n",
        "print(\"RF:\", accuracy_score(y_test, rf.predict(X_test)))\n",
        "print(\"XGB:\", accuracy_score(y_test, xgb.predict(X_test)))\n",
        "print(\"Voting:\", accuracy_score(y_test, voting.predict(X_test)))\n",
        "\n",
        "# ============================================================\n",
        "# 4. FEATURE EXTRACTOR (URL + HTML Content)\n",
        "# ============================================================\n",
        "\n",
        "def extract_features(url):\n",
        "    features = {}\n",
        "    parsed = urlparse(url)\n",
        "    domain = parsed.netloc\n",
        "    domain_only = domain.replace(\"www.\", \"\")\n",
        "\n",
        "    # --- URL FEATURES ---\n",
        "    features['having_IP_Address'] = 1 if re.match(r'\\d+\\.\\d+\\.\\d+\\.\\d+', domain) else -1\n",
        "\n",
        "    L = len(url)\n",
        "    features['URL_Length'] = 1 if L > 75 else (0 if 54 <= L <= 75 else -1)\n",
        "\n",
        "    shorteners = r\"(bit\\.ly|goo\\.gl|tinyurl|shorte\\.st|t\\.co|is\\.gd|ow\\.ly)\"\n",
        "    features['Shortining_Service'] = 1 if re.search(shorteners, url) else -1\n",
        "\n",
        "    features['having_At_Symbol'] = 1 if \"@\" in url else -1\n",
        "    features['double_slash_redirecting'] = 1 if url.count(\"//\") > 1 else -1\n",
        "    features['Prefix_Suffix'] = 1 if \"-\" in domain else -1\n",
        "\n",
        "    dots = domain.count(\".\")\n",
        "    features['having_Sub_Domain'] = 1 if dots >= 3 else (0 if dots == 2 else -1)\n",
        "\n",
        "    features['HTTPS_token'] = 1 if \"https\" in domain.lower() else -1\n",
        "    features['port'] = 1 if parsed.port not in [80, 443, None] else -1\n",
        "    features['SSLfinal_State'] = 1 if parsed.scheme == \"https\" else -1\n",
        "\n",
        "    # --- HTML FETCH ---\n",
        "    try:\n",
        "        response = requests.get(url, timeout=4)\n",
        "        html = response.text\n",
        "        soup = BeautifulSoup(html, \"lxml\")\n",
        "    except:\n",
        "        # Fill missing HTML features\n",
        "        for col in X.columns:\n",
        "            if col not in features:\n",
        "                features[col] = 0\n",
        "        return features\n",
        "\n",
        "    # ------------------------------\n",
        "    # HTML CONTENT FEATURES\n",
        "    # ------------------------------\n",
        "\n",
        "    # Collect tags\n",
        "    anchors = soup.find_all(\"a\", href=True)\n",
        "    imgs = soup.find_all(\"img\", src=True)\n",
        "    scripts = soup.find_all(\"script\", src=True)\n",
        "    links = soup.find_all(\"link\", href=True)\n",
        "    iframes = soup.find_all(\"iframe\")\n",
        "\n",
        "    # --- Request_URL ---\n",
        "    total = len(imgs) + len(scripts)\n",
        "    external = 0\n",
        "    for tag in imgs + scripts:\n",
        "        src = tag.get(\"src\")\n",
        "        if src and src.startswith(\"http\") and domain_only not in src:\n",
        "            external += 1\n",
        "    ratio = external / total if total != 0 else 0\n",
        "    features[\"Request_URL\"] = 1 if ratio > 0.61 else (0 if 0.22 <= ratio <= 0.61 else -1)\n",
        "\n",
        "    # --- URL_of_Anchor ---\n",
        "    total = len(anchors)\n",
        "    external = 0\n",
        "    for a in anchors:\n",
        "        href = a[\"href\"]\n",
        "        if href.startswith(\"http\") and domain_only not in href:\n",
        "            external += 1\n",
        "    ratio = external / total if total != 0 else 0\n",
        "    features[\"URL_of_Anchor\"] = 1 if ratio > 0.67 else (0 if ratio >= 0.31 else -1)\n",
        "\n",
        "    # --- Links_in_tags ---\n",
        "    total = len(scripts) + len(links)\n",
        "    external = 0\n",
        "    for tag in scripts + links:\n",
        "        src = tag.get(\"src\") or tag.get(\"href\")\n",
        "        if src and src.startswith(\"http\") and domain_only not in src:\n",
        "            external += 1\n",
        "    ratio = external / total if total else 0\n",
        "    features[\"Links_in_tags\"] = 1 if ratio > 0.61 else (0 if ratio >= 0.22 else -1)\n",
        "\n",
        "    # --- SFH ---\n",
        "    forms = soup.find_all(\"form\")\n",
        "    if len(forms) == 0:\n",
        "        features[\"SFH\"] = 1\n",
        "    else:\n",
        "        action = forms[0].get(\"action\", \"\")\n",
        "        if action in [\"\", \"about:blank\"]:\n",
        "            features[\"SFH\"] = 1\n",
        "        elif domain_only not in action:\n",
        "            features[\"SFH\"] = 1\n",
        "        else:\n",
        "            features[\"SFH\"] = -1\n",
        "\n",
        "    features[\"Submitting_to_email\"] = 1 if \"mailto:\" in html else -1\n",
        "    features[\"Abnormal_URL\"] = -1 if domain_only in html else 1\n",
        "\n",
        "    features[\"Redirect\"] = 1 if \"window.location\" in html or \"meta refresh\" in html.lower() else -1\n",
        "    features[\"on_mouseover\"] = 1 if \"onmouseover\" in html.lower() else -1\n",
        "    features[\"RightClick\"] = 1 if \"event.button==2\" in html else -1\n",
        "    features[\"popUpWidnow\"] = 1 if \"window.open\" in html else -1\n",
        "    features[\"Iframe\"] = 1 if len(iframes) > 0 else -1\n",
        "\n",
        "    # Fill missing\n",
        "    for col in X.columns:\n",
        "        if col not in features:\n",
        "            features[col] = 0\n",
        "\n",
        "    return features\n",
        "\n",
        "# ============================================================\n",
        "# 5. FINAL PREDICTION FUNCTION\n",
        "# ============================================================\n",
        "\n",
        "def predict_url(url):\n",
        "    feat = extract_features(url)\n",
        "    feat_df = pd.DataFrame([feat])[X.columns]\n",
        "\n",
        "    prob = voting.predict_proba(feat_df)[0]\n",
        "    pred = voting.predict(feat_df)[0]\n",
        "\n",
        "    print(\"\\n======================================\")\n",
        "    print(\"URL:\", url)\n",
        "    print(\"Phishing Probability:\", prob[1])\n",
        "    print(\"Prediction:\", \"PHISHING\" if pred == 1 else \"LEGITIMATE\")\n",
        "    print(\"======================================\\n\")\n",
        "\n",
        "    return {\"url\": url, \"prob\": prob[1], \"prediction\": \"PHISHING\" if pred == 1 else \"LEGITIMATE\"}\n",
        "\n",
        "# ============================================================\n",
        "# 6. TEST URLs\n",
        "# ============================================================\n",
        "\n",
        "test_urls = [\n",
        "    \"https://google.com\",\n",
        "    \"http://198.54.23.11/login/secure\",\n",
        "    \"https://paypal-security-update.com/login\",\n",
        "    \"http://bit.ly/3xYz\"\n",
        "]\n",
        "\n",
        "for u in test_urls:\n",
        "    predict_url(u)\n",
        "\n",
        "print(\"System Ready. Use predict_url('your_url') to check any site.\")"
      ]
    }
  ]
}