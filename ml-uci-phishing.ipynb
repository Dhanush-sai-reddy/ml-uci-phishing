{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dhanush-sai-reddy/ml-uci-phishing/blob/main/ml-uci-phishing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f102367-d0af-4276-b1cd-a7fb90aa8947",
      "metadata": {
        "id": "7f102367-d0af-4276-b1cd-a7fb90aa8947"
      },
      "outputs": [],
      "source": [
        "\n",
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"isatish/phishing-dataset-uci-ml-csv\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "for file in os.listdir(path):\n",
        "    if file.endswith(\".csv\"):\n",
        "        csv_path = os.path.join(path, file)\n",
        "        break\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e2aa0c8"
      },
      "source": [
        "def predict_combined_url(url):\n",
        "    url_feats = extract_url_features(url)\n",
        "    content_feats = extract_content_features(url)\n",
        "\n",
        "    # Combine all features, ensuring correct order based on all_features list\n",
        "    combined_data = {**url_feats, **content_feats}\n",
        "    # Ensure features are in the same order as `X_combined` used for training\n",
        "    df_predict = pd.DataFrame([combined_data])[all_features]\n",
        "\n",
        "    # Make prediction using the hybrid model\n",
        "    prediction = hybrid_combined.predict(df_predict)[0]\n",
        "\n",
        "    if prediction == 0:\n",
        "        print(\"ðŸ”´ PHISHING URL\")\n",
        "    else:\n",
        "        print(\"ðŸŸ¢ LEGITIMATE URL\")"
      ],
      "id": "9e2aa0c8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df2f5e41"
      },
      "source": [
        "Let's test the new `predict_combined_url` function with a known phishing URL and a legitimate URL."
      ],
      "id": "df2f5e41"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6011487-0737-4cca-974e-744f81705a1f",
      "metadata": {
        "id": "d6011487-0737-4cca-974e-744f81705a1f"
      },
      "outputs": [],
      "source": [
        "df = df.drop(\"id\", axis=1)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8ecdc4e-e225-4a85-b09b-75fec8387c88",
      "metadata": {
        "id": "a8ecdc4e-e225-4a85-b09b-75fec8387c88"
      },
      "outputs": [],
      "source": [
        "url_features = [\n",
        "    \"having_IP_Address\",\n",
        "    \"URL_Length\",\n",
        "    \"Shortining_Service\",\n",
        "    \"having_At_Symbol\",\n",
        "    \"double_slash_redirecting\",\n",
        "    \"Prefix_Suffix\",\n",
        "    \"having_Sub_Domain\",\n",
        "    \"SSLfinal_State\",\n",
        "    \"Domain_registeration_length\",\n",
        "    \"HTTPS_token\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3f2a7ad-1885-4171-8c8a-3ad7f67d6be4",
      "metadata": {
        "id": "e3f2a7ad-1885-4171-8c8a-3ad7f67d6be4"
      },
      "outputs": [],
      "source": [
        "X = df[url_features]\n",
        "y = df[\"Result\"]\n",
        "\n",
        "X.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57f01940-4c63-4a90-9928-bf8961b10a01",
      "metadata": {
        "id": "57f01940-4c63-4a90-9928-bf8961b10a01"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a43db0d7-6ce1-4962-81af-831ee876dcd2",
      "metadata": {
        "id": "a43db0d7-6ce1-4962-81af-831ee876dcd2"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(n_estimators=150)\n",
        "rf.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adcab584-fb69-4942-830c-ea55b35b76e8",
      "metadata": {
        "id": "adcab584-fb69-4942-830c-ea55b35b76e8"
      },
      "outputs": [],
      "source": [
        "pred = rf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74be7ada-c4df-47a1-997e-7d579b61952c",
      "metadata": {
        "id": "74be7ada-c4df-47a1-997e-7d579b61952c"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4c5c296-4d64-43a0-bbca-e5f33786ca7d",
      "metadata": {
        "id": "e4c5c296-4d64-43a0-bbca-e5f33786ca7d"
      },
      "outputs": [],
      "source": [
        "!pip install tldextract\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85755693-a8ee-44b7-90a8-8db7d0186f6b",
      "metadata": {
        "id": "85755693-a8ee-44b7-90a8-8db7d0186f6b"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import tldextract\n",
        "import requests\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "\n",
        "def extract_url_features(url):\n",
        "    # -------------------------------\n",
        "    # 1. having_IP_Address\n",
        "    # -------------------------------\n",
        "    ip_pattern = r'\\d+\\.\\d+\\.\\d+\\.\\d+'\n",
        "    having_ip = -1 if re.search(ip_pattern, url) else 1\n",
        "\n",
        "    # -------------------------------\n",
        "    # 2. URL_Length\n",
        "    # -------------------------------\n",
        "    url_len = len(url)\n",
        "    if url_len < 54:\n",
        "        url_length = 1\n",
        "    elif 54 <= url_len <= 75:\n",
        "        url_length = 0\n",
        "    else:\n",
        "        url_length = -1\n",
        "\n",
        "    # -------------------------------\n",
        "    # 3. Shortining_Service\n",
        "    # -------------------------------\n",
        "    shorteners = [\"bit.ly\", \"tinyurl\", \"goo.gl\", \"t.co\", \"is.gd\", \"buff.ly\"]\n",
        "    short_service = -1 if any(s in url for s in shorteners) else 1\n",
        "\n",
        "    # -------------------------------\n",
        "    # 4. having_At_Symbol\n",
        "    # -------------------------------\n",
        "    at_symbol = -1 if \"@\" in url else 1\n",
        "\n",
        "    # -------------------------------\n",
        "    # 5. double_slash_redirecting\n",
        "    # -------------------------------\n",
        "    pos = url.find(\"//\")\n",
        "    double_slash = -1 if pos > 6 else 1\n",
        "\n",
        "    # -------------------------------\n",
        "    # 6. Prefix_Suffix (- in domain)\n",
        "    # -------------------------------\n",
        "    prefix_suffix = -1 if \"-\" in url else 1\n",
        "\n",
        "    # -------------------------------\n",
        "    # 7. having_Sub_Domain\n",
        "    # -------------------------------\n",
        "    ext = tldextract.extract(url)\n",
        "    sub = ext.subdomain\n",
        "\n",
        "    if sub == \"\":\n",
        "        subdomain = 1\n",
        "    elif sub.count(\".\") == 0:\n",
        "        subdomain = 0\n",
        "    else:\n",
        "        subdomain = -1\n",
        "\n",
        "    # -------------------------------\n",
        "    # 8. SSLfinal_State (https or http)\n",
        "    # -------------------------------\n",
        "    if url.startswith(\"https\"):\n",
        "        SSLfinal_State = 1   # secure\n",
        "    else:\n",
        "        SSLfinal_State = -1  # insecure\n",
        "\n",
        "    # -------------------------------\n",
        "    # 9. Domain_registeration_length (approximation)\n",
        "    # -------------------------------\n",
        "    # Real domain age requires WHOIS, we approximate:\n",
        "    domain = ext.domain + \".\" + ext.suffix\n",
        "    if len(domain) < 5:\n",
        "        Domain_registration_length = -1\n",
        "    else:\n",
        "        Domain_registration_length = 1\n",
        "\n",
        "    # -------------------------------\n",
        "    # 10. HTTPS_token (fake https inside URL)\n",
        "    # -------------------------------\n",
        "    if \"https\" in url[8:]:  # after http://\n",
        "        HTTPS_token = -1\n",
        "    else:\n",
        "        HTTPS_token = 1\n",
        "\n",
        "    return {\n",
        "        \"having_IP_Address\": having_ip,\n",
        "        \"URL_Length\": url_length,\n",
        "        \"Shortining_Service\": short_service,\n",
        "        \"having_At_Symbol\": at_symbol,\n",
        "        \"double_slash_redirecting\": double_slash,\n",
        "        \"Prefix_Suffix\": prefix_suffix,\n",
        "        \"having_Sub_Domain\": subdomain,\n",
        "        \"SSLfinal_State\": SSLfinal_State,\n",
        "        \"Domain_registeration_length\": Domain_registration_length,\n",
        "        \"HTTPS_token\": HTTPS_token\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61cc2ca2-5071-4d10-b834-611a0e1beaa1",
      "metadata": {
        "id": "61cc2ca2-5071-4d10-b834-611a0e1beaa1"
      },
      "outputs": [],
      "source": [
        "def predict_url(url):\n",
        "    features = extract_url_features(url)\n",
        "    df_test = pd.DataFrame([features])\n",
        "    result = rf.predict(df_test)[0]\n",
        "\n",
        "    if result == -1:\n",
        "        print(\"ðŸ”´ PHISHING URL\")\n",
        "    else:\n",
        "        print(\"ðŸŸ¢ LEGITIMATE URL\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80990867-b0a6-43df-ba61-f0aed09a83a5",
      "metadata": {
        "id": "80990867-b0a6-43df-ba61-f0aed09a83a5"
      },
      "outputs": [],
      "source": [
        "predict_url(\"http://paypal.com.verify-update-security-login.com\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f82bcec5-0a19-40ef-9f09-94c645ff9bd9",
      "metadata": {
        "id": "f82bcec5-0a19-40ef-9f09-94c645ff9bd9"
      },
      "outputs": [],
      "source": [
        "predict_url(\"www.google.com\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a7b1d25-a7db-4770-b1e2-b8e9fbffbf7b",
      "metadata": {
        "id": "7a7b1d25-a7db-4770-b1e2-b8e9fbffbf7b"
      },
      "outputs": [],
      "source": [
        "predict_url(\"https://chatgpt.com/c/6917625d-fd3c-8324-99f2-e556b96116fe\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0beaa42a-17b4-49d7-bbc7-4c1a8e1e8e3f",
      "metadata": {
        "id": "0beaa42a-17b4-49d7-bbc7-4c1a8e1e8e3f"
      },
      "outputs": [],
      "source": [
        "predict_url(\"https://www.lenovo.com/in/en/p/accessories-and-software/chargers-and-batteries/chargers/gx20p92532\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df367b6e-d70d-4926-96ba-5a23e6859f1b",
      "metadata": {
        "id": "df367b6e-d70d-4926-96ba-5a23e6859f1b"
      },
      "outputs": [],
      "source": [
        "content_features = [\n",
        "    \"Request_URL\",\n",
        "    \"URL_of_Anchor\",\n",
        "    \"Links_in_tags\",\n",
        "    \"SFH\",\n",
        "    \"Redirect\",\n",
        "    \"popUpWidnow\",\n",
        "    \"Iframe\",\n",
        "    \"age_of_domain\",\n",
        "    \"DNSRecord\",\n",
        "    \"web_traffic\",\n",
        "    \"Page_Rank\",\n",
        "    \"Google_Index\"\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b64b912-f89d-47ef-85e5-905c35816a41",
      "metadata": {
        "id": "3b64b912-f89d-47ef-85e5-905c35816a41"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBClassifier\n",
        "xgb = XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=5,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    eval_metric='logloss'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3f8ae56-e32f-42d6-8496-823f53dba536",
      "metadata": {
        "id": "c3f8ae56-e32f-42d6-8496-823f53dba536"
      },
      "outputs": [],
      "source": [
        "# Convert labels for XGBoost and Hybrid model\n",
        "y_train_xgb = y_train.replace({-1: 0})\n",
        "y_test_xgb  = y_test.replace({-1: 0})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b22c930-4516-400f-9b5e-07fbab8f9990",
      "metadata": {
        "id": "9b22c930-4516-400f-9b5e-07fbab8f9990"
      },
      "outputs": [],
      "source": [
        "xgb.fit(X_train, y_train_xgb)\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "hybrid = VotingClassifier(\n",
        "    estimators=[(\"rf\", rf), (\"xgb\", xgb)],\n",
        "    voting=\"soft\"\n",
        ")\n",
        "\n",
        "# Remember: XGBoost needs labels 0/1, not -1/1\n",
        "y_hybrid = y.replace({-1: 0})\n",
        "\n",
        "hybrid.fit(X, y_hybrid)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb53ff0e-4cc8-49e1-8394-dbe3baf746ed",
      "metadata": {
        "id": "fb53ff0e-4cc8-49e1-8394-dbe3baf746ed"
      },
      "outputs": [],
      "source": [
        "pred = hybrid.predict(X_test)\n",
        "\n",
        "pred_final = pd.Series(pred).replace({0: -1})\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "print(\"Accuracy:\", accuracy_score(y_test, pred_final))\n",
        "print(classification_report(y_test, pred_final))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c7278b4-e301-4126-898d-b961506f6a38",
      "metadata": {
        "id": "4c7278b4-e301-4126-898d-b961506f6a38"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urlparse\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b761cabb-eebe-4122-8bf3-0d63cf8ee250",
      "metadata": {
        "id": "b761cabb-eebe-4122-8bf3-0d63cf8ee250"
      },
      "outputs": [],
      "source": [
        "def scrape_page(url):\n",
        "    try:\n",
        "        r = requests.get(url, timeout=5, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
        "        return r.text\n",
        "    except:\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c8c0bfec-1694-4040-80e5-6a2eff0ce78d",
      "metadata": {
        "id": "c8c0bfec-1694-4040-80e5-6a2eff0ce78d"
      },
      "outputs": [],
      "source": [
        "def get_soup(url):\n",
        "    html = scrape_page(url)\n",
        "    if html is None:\n",
        "        return None\n",
        "    return BeautifulSoup(html, \"html.parser\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c40c4aac-c34f-4155-be12-cb44453448f1",
      "metadata": {
        "id": "c40c4aac-c34f-4155-be12-cb44453448f1"
      },
      "outputs": [],
      "source": [
        "def count_external_links(soup, domain):\n",
        "    if soup is None:\n",
        "        return 0\n",
        "\n",
        "    links = soup.find_all(\"a\", href=True)\n",
        "    count = 0\n",
        "    for tag in links:\n",
        "        try:\n",
        "            if domain not in tag[\"href\"]:\n",
        "                count += 1\n",
        "        except:\n",
        "            pass\n",
        "    return count\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d73ac02d-930a-486c-afde-fc87f80e88ae",
      "metadata": {
        "id": "d73ac02d-930a-486c-afde-fc87f80e88ae"
      },
      "outputs": [],
      "source": [
        "def count_iframes(soup):\n",
        "    if soup is None:\n",
        "        return 0\n",
        "    return len(soup.find_all(\"iframe\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "786da94f-5516-46e1-8559-d031041c4ef0",
      "metadata": {
        "id": "786da94f-5516-46e1-8559-d031041c4ef0"
      },
      "outputs": [],
      "source": [
        "def count_popups(soup):\n",
        "    if soup is None:\n",
        "        return 0\n",
        "    scripts = soup.find_all(\"script\")\n",
        "    count = 0\n",
        "    for s in scripts:\n",
        "        code = s.text.lower()\n",
        "        if \"window.open\" in code or \"alert(\" in code:\n",
        "            count += 1\n",
        "    return count\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bfc0804-a5d4-4479-b387-a3d041ba967b",
      "metadata": {
        "id": "4bfc0804-a5d4-4479-b387-a3d041ba967b"
      },
      "outputs": [],
      "source": [
        "def right_click_disabled(soup):\n",
        "    if soup is None:\n",
        "        return 0\n",
        "    page = str(soup).lower()\n",
        "    return 1 if \"event.button==2\" in page or \"contextmenu\" in page else 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2c8ef7e-8eb9-42e0-aa11-9544caa38ad5",
      "metadata": {
        "id": "f2c8ef7e-8eb9-42e0-aa11-9544caa38ad5"
      },
      "outputs": [],
      "source": [
        "def detect_redirect(soup):\n",
        "    if soup is None:\n",
        "        return 0\n",
        "    meta = soup.find(\"meta\", attrs={\"http-equiv\": \"refresh\"})\n",
        "    return 1 if meta else 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82d6ce1e-0db9-4022-8859-214f032506d9",
      "metadata": {
        "id": "82d6ce1e-0db9-4022-8859-214f032506d9"
      },
      "outputs": [],
      "source": [
        "def extract_content_features(url):\n",
        "    soup = get_soup(url)\n",
        "    domain = urlparse(url).netloc\n",
        "\n",
        "    # Default values for features that are hard to extract without external APIs\n",
        "    # Assigning '1' as a neutral/legitimate indicator for now,\n",
        "    # as the original dataset uses -1, 0, 1 and '1' generally means legitimate.\n",
        "    # These would ideally require more sophisticated methods (WHOIS, DNS lookup, etc.)\n",
        "    age_of_domain = 1\n",
        "    DNSRecord = 1\n",
        "    web_traffic = 1\n",
        "    Page_Rank = 1\n",
        "    Google_Index = 1\n",
        "\n",
        "    # --- Features that can be extracted or approximated from content ----\n",
        "    iframe_feature = count_iframes(soup)\n",
        "    popup_feature = count_popups(soup)\n",
        "    redirect_feature = detect_redirect(soup)\n",
        "\n",
        "    Request_URL = 1 # Simplified: default to legitimate\n",
        "    URL_of_Anchor = 1 # Simplified: default to legitimate\n",
        "    Links_in_tags = 1 # Simplified: default to legitimate\n",
        "    SFH = 1 # Simplified: default to legitimate\n",
        "\n",
        "    if soup:\n",
        "        # Request_URL: Proportion of objects requested from external URL\n",
        "        # For simplicity, count external links in images, scripts, etc.\n",
        "        total_objects = 0\n",
        "        external_objects = 0\n",
        "        for tag in soup.find_all(['img', 'script', 'link']):\n",
        "            src_or_href = tag.get('src') or tag.get('href')\n",
        "            if src_or_href:\n",
        "                total_objects += 1\n",
        "                parsed_src_or_href = urlparse(src_or_href)\n",
        "                if parsed_src_or_href.netloc and parsed_src_or_href.netloc != domain:\n",
        "                    external_objects += 1\n",
        "        if total_objects > 0:\n",
        "            if (external_objects / total_objects) > 0.5: # Arbitrary threshold\n",
        "                Request_URL = -1\n",
        "            elif (external_objects / total_objects) > 0:\n",
        "                Request_URL = 0\n",
        "            else:\n",
        "                Request_URL = 1\n",
        "        else:\n",
        "            Request_URL = 1 # No objects found, consider legitimate\n",
        "\n",
        "        # URL_of_Anchor: Percentage of anchor tags pointing to different domains\n",
        "        all_anchors = soup.find_all('a', href=True)\n",
        "        total_anchors = len(all_anchors)\n",
        "        external_anchors = 0\n",
        "        if total_anchors > 0:\n",
        "            for anchor in all_anchors:\n",
        "                href = anchor['href']\n",
        "                parsed_href = urlparse(href)\n",
        "                if parsed_href.netloc and parsed_href.netloc != domain:\n",
        "                    external_anchors += 1\n",
        "            if (external_anchors / total_anchors) > 0.6: # Arbitrary threshold\n",
        "                URL_of_Anchor = -1\n",
        "            elif (external_anchors / total_anchors) > 0.3:\n",
        "                URL_of_Anchor = 0\n",
        "            else:\n",
        "                URL_of_Anchor = 1\n",
        "        else:\n",
        "            URL_of_Anchor = 1 # No anchors found, consider legitimate\n",
        "\n",
        "        # Links_in_tags: Percentage of links contained in <meta>, <script>, and <link> tags\n",
        "        meta_script_link_tags = soup.find_all(['meta', 'script', 'link'], href=True) + soup.find_all('script', src=True)\n",
        "        total_tags = len(meta_script_link_tags)\n",
        "        external_links_in_tags = 0\n",
        "        if total_tags > 0:\n",
        "            for tag in meta_script_link_tags:\n",
        "                href_or_src = tag.get('href') or tag.get('src')\n",
        "                if href_or_src:\n",
        "                    parsed_link = urlparse(href_or_src)\n",
        "                    if parsed_link.netloc and parsed_link.netloc != domain:\n",
        "                        external_links_in_tags += 1\n",
        "            if (external_links_in_tags / total_tags) > 0.5:\n",
        "                Links_in_tags = -1\n",
        "            elif (external_links_in_tags / total_tags) > 0:\n",
        "                Links_in_tags = 0\n",
        "            else:\n",
        "                Links_in_tags = 1\n",
        "        else:\n",
        "            Links_in_tags = 1 # No relevant tags found, consider legitimate\n",
        "\n",
        "        # SFH (Server Form Handler): If the form action is to an external domain or is blank.\n",
        "        forms = soup.find_all('form')\n",
        "        if forms:\n",
        "            sfh_suspicious = False\n",
        "            for form in forms:\n",
        "                action = form.get('action')\n",
        "                if action is None or action == '': # Blank action is suspicious\n",
        "                    sfh_suspicious = True\n",
        "                    break\n",
        "                parsed_action = urlparse(action)\n",
        "                if parsed_action.netloc and parsed_action.netloc != domain: # External action is suspicious\n",
        "                    sfh_suspicious = True\n",
        "                    break\n",
        "            if sfh_suspicious:\n",
        "                SFH = -1\n",
        "            else:\n",
        "                SFH = 1\n",
        "        else:\n",
        "            SFH = 1 # No forms, consider legitimate\n",
        "\n",
        "    return {\n",
        "        \"Request_URL\": Request_URL,\n",
        "        \"URL_of_Anchor\": URL_of_Anchor,\n",
        "        \"Links_in_tags\": Links_in_tags,\n",
        "        \"SFH\": SFH,\n",
        "        \"Redirect\": redirect_feature,\n",
        "        \"popUpWidnow\": popup_feature,\n",
        "        \"Iframe\": iframe_feature,\n",
        "        \"age_of_domain\": age_of_domain,\n",
        "        \"DNSRecord\": DNSRecord,\n",
        "        \"web_traffic\": web_traffic,\n",
        "        \"Page_Rank\": Page_Rank,\n",
        "        \"Google_Index\": Google_Index\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa55b781-6b71-4998-a438-7ab371d967dc",
      "metadata": {
        "id": "aa55b781-6b71-4998-a438-7ab371d967dc"
      },
      "outputs": [],
      "source": [
        "url = \"https://www.google.com\"\n",
        "features = extract_content_features(url)\n",
        "features\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2737e5d8"
      },
      "source": [
        "all_features = url_features + content_features\n",
        "all_features = list(set(all_features))\n",
        "\n",
        "print(\"Combined features (no duplicates):\", all_features)"
      ],
      "id": "2737e5d8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1687d67"
      },
      "source": [
        "X_combined = df[all_features]\n",
        "y_combined = df[\"Result\"]\n",
        "\n",
        "X_combined.head()"
      ],
      "id": "b1687d67",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7452c51"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_combined, X_test_combined, y_train_combined, y_test_combined = train_test_split(\n",
        "    X_combined, y_combined, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Data split into training and testing sets.\")"
      ],
      "id": "e7452c51",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6ce7ad4"
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "y_train_combined_xgb = y_train_combined.replace({-1: 0})\n",
        "y_test_combined_xgb  = y_test_combined.replace({-1: 0})\n",
        "\n",
        "xgb_combined = XGBClassifier(\n",
        "    n_estimators=300,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=5,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "xgb_combined.fit(X_train_combined, y_train_combined_xgb)\n",
        "print(\"XGBoost model trained on combined features.\")"
      ],
      "id": "a6ce7ad4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92bf29e6"
      },
      "source": [
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "y_hybrid_combined = y_combined.replace({-1: 0})\n",
        "\n",
        "hybrid_combined = VotingClassifier(\n",
        "    estimators=[(\"rf_combined\", rf_combined), (\"xgb_combined\", xgb_combined)],\n",
        "    voting=\"soft\"\n",
        ")\n",
        "\n",
        "hybrid_combined.fit(X_combined, y_hybrid_combined)\n",
        "print(\"Hybrid model trained on combined features.\")"
      ],
      "id": "92bf29e6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ed6da09"
      },
      "source": [
        "pred_hybrid_combined = hybrid_combined.predict(X_test_combined)\n",
        "pred_hybrid_combined_final = pd.Series(pred_hybrid_combined).replace({0: -1})\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "print(\"Accuracy:\", accuracy_score(y_test_combined, pred_hybrid_combined_final))\n",
        "print(classification_report(y_test_combined, pred_hybrid_combined_final))"
      ],
      "id": "9ed6da09",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}